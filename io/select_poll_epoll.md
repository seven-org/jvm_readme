# select & poll & epoll

## 前言
- `select` `poll` `epoll` 均为计算机系统底层方法 不同系统的实现不相同
- `select` `poll` `epoll` 均为 **IO多路复用** 的实现 可以监视多个描述符，一旦某个描述符就绪（读或写就绪），能够通知程序进行相应读写操作
- 下面fd即文件描述符,也可以理解为socket

## select
- select函数仅仅知道有几个I/O事件发生了，但并不知道具体是哪几个socket连接有I/O事件，还需要**轮询去查找**，时间复杂度为**O(n)**，处理的请求数越多，所消耗的时间越长。

- 执行流程:
    1. 从用户空间拷贝 fd_set(注册的事件的集合) 到内核空间
    2. 遍历所有的 fd 文件，并将当前进程挂到每个 fd 的等待队列中，当某个 fd 文件设备收到消息后，会唤醒设备等待队列上休眠的进程
    3. 如果遍历完所有的 fd 文件 没有 IO 事件，则当前进程进入睡眠，当某个 fd 文件有 IO事件或者睡眠时间超时后，当前进程重新唤醒再次执行步骤2

- 缺点:
    - 单个进程能打开的 fd 文件数量是有限的(**能监听端口的多少有限**)，通过 fd_setsize 设置，32位机器默认1024，64位机器默认2048
    - 每次调用时需要将 fd_set 从用户态复制到内核态，当 fd 文件很多时**用户空间和内核空间复制开销大**
    - 每次调用时需要将进程加入到所有 监视进程的等待队列，每次唤醒又需要从每个队列中移除(**轮询**)
    - 每次调用前都要对参数进行重新设定，会降低性能
    - 每次被唤醒需要重新遍历等待队列

## poll
- 时间复杂度O(n)
- poll**和select类似**，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它**没有最大连接数的限制**，原因是它是基于链表来存储的

## epoll
> epoll可以理解为event pool，不同与select、poll的轮询机制，epoll采用的是**事件驱动**机制，每个fd上有注册有回调函数，当网卡接收到数据时会回调该函数，同时将该fd的引用放入rdlist就绪列表中。
> 当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。

- 特征:
    - 时间复杂度O(1)
    - epoll 支持的最大文件描述符上限是整个系统最大可打开的文件数目, 1G内存理论上最大创建10万个文件描述符(端口)
    - 内存拷贝，epoll使用`mmap`减少复制开销
    - select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次
    - 每个文件描述符上都有一个callback函数，当socket有事件发生时会回调这个函数将该fd的引用添加到就绪列表中，select和poll并不会明确指出是哪些文件描述符就绪，而epoll会。造成的区别就是，系统调用返回后，调用select和poll的程序需要遍历监听的整个文件描述符找到是谁处于就绪，而epoll则直接处理即可
    - select、poll采用轮询的方式来检查文件描述符是否处于就绪态，而epoll采用回调机制。造成的结果就是，随着fd的增加，select和poll的效率会线性降低，而epoll不会受到太大影响，除非活跃的socket很多

epoll中一组函数通过这三个函数之间的配合完成处理百万级别的连接
- epoll 函数:
    - epoll_create() 在Linux内核里面申请一个文件系统 红黑树，返回epoll对象，也是一个fd
    - epoll_ctl() 操作epoll对象，在这个对象里面修改/添加/删除对应的链接fd, 绑定一个callback函数
    - epoll_wait() 等待其管理的连接上的 IO 事件

- 步骤:
    1. 注册事件 通过 epoll_ctl实现 对于服务器而言，是 accept，read，write 三种事件; 对于客户端而言，是 connect，read，write 三种事件
    1. 轮询这三个事件是否就绪.通过函数epoll_wait实现.有事件发生就返回,这里的轮询不是轮询整个fd,是轮询我们的就绪事件列表有没有事件发生
    1. 事件就绪,执行实际的I/O操作.通过函数accept/read/write实现
        - read事件就绪:远程有数据来了,socket读缓冲区里有数据,需要调用read函数处理.
        - write事件就绪:指本地的socket写缓冲区是否可写.如果缓冲区没满,则一直是可写的,write事件是一直就绪的,可以调用write函数,只有发送大文件时,socket写缓冲区被占满,write事件才不是就绪状态.
        - accpet事件就绪:有新的连接进入,需要调用accept函数处理.

###### epolllt(水平触发) & epollet(边缘触发)


## select poll epoll 区别表格对照
| | select | poll | epoll|
| -- | -- | -- | -- |
| 性能 | 随着连接数的增加，性能急剧下降，处理成千上万的并发连接数时，性能很差 | 随着连接数的增加，性能急剧下降，处理成千上万的并发连接数时，性能很差 | 随着连接数的增加，性能基本没有变化 |
| 连接数 | 32位机器默认1024，64位机器默认2048 | 无限制(系统资源限制) | 无限制(系统资源限制) |
| 内存拷贝 | 每次调用select拷贝 | 每次调用poll拷贝 | fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝 |
| 数据结构 | bitmap | 数组 | 红黑树 |
| 内在处理机制 | 线性轮询 | 线性轮询 | FD挂在红黑树，通过事件回调callback |
| 时间复杂度 | O(n) | O(n) | O(1) |
